{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.models.eval_model' from '/home/mas-server/etu/nn/paraphrase_detection/notebooks/../src/models/eval_model.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import mlflow\n",
    "import importlib\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.data import datasets\n",
    "from src import models\n",
    "\n",
    "importlib.reload(datasets)\n",
    "importlib.reload(models)\n",
    "importlib.reload(models.lstm_models)\n",
    "importlib.reload(models.train_model)\n",
    "importlib.reload(models.eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/mas-server/etu/nn/paraphrase_detection/notebooks/mlruns/1', creation_time=1711035737638, experiment_id='1', last_update_time=1711035737638, lifecycle_stage='active', name='lstms', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"lstms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mas-server/anaconda3/envs/ocean/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\", use_fast=True)\n",
    "data_dir = '../data/processed'\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "text_datasets = {\n",
    "    x: datasets.ParaphraseDataset(\n",
    "        pd.read_csv(data_dir + \"/\" + x + \".csv\"),\n",
    "        tokenizer,\n",
    "        256\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        text_datasets[x], batch_size = 1024,\n",
    "        shuffle=True, num_workers = 12\n",
    "    )\n",
    "    for x in [TRAIN, VAL, TEST]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlflow_experiment(\n",
    "    exp_name,\n",
    "    model_config_path,\n",
    "    dataloaders,\n",
    "    epochs\n",
    "):\n",
    "    with open(model_config_path, \"r\") as f:\n",
    "        model_config = json.load(f)\n",
    "    model_type = model_config.get(\"type\", \"No type in config\")\n",
    "    if model_type == \"lstm\":\n",
    "        model = models.lstm_models.build_SimpleBiLSTM(model_config)\n",
    "    elif model_type == \"residual_lstm\":\n",
    "        raise NotImplemented()\n",
    "    elif model_type == \"transformers\":\n",
    "        raise NotImplemented()\n",
    "    with mlflow.start_run(run_name=exp_name):\n",
    "        model.to(\"cuda\")\n",
    "        mlflow.log_params(model_config)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.set_tag(\"model_name\", model_type)\n",
    "        model = models.train_model.train_model(\n",
    "            model,\n",
    "            torch.nn.BCEWithLogitsLoss(),\n",
    "            optim.Adam(model.parameters()),\n",
    "            dataloaders,\n",
    "            epochs\n",
    "        )\n",
    "        models.eval_model.eval_model(model, dataloaders)\n",
    "        mlflow.pytorch.log_model(model, \"torch_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lstm1.json', 'lstm2.json', 'lstm0.json']\n"
     ]
    }
   ],
   "source": [
    "config_paths = \"../models/\"\n",
    "configs = [x for x in os.listdir(config_paths) if x.endswith(\".json\")]\n",
    "print(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10\n",
      "----------\n",
      "Training batch 552/553\n",
      "Validation batch 0/119"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'update'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conf \u001b[38;5;129;01min\u001b[39;00m configs:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mrun_mlflow_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mrun_mlflow_experiment\u001b[0;34m(exp_name, model_config_path, dataloaders, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs)\n\u001b[1;32m     20\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_type)\n\u001b[0;32m---> 21\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCEWithLogitsLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m models\u001b[38;5;241m.\u001b[39meval_model\u001b[38;5;241m.\u001b[39meval_model(model, dataloaders)\n\u001b[1;32m     29\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mpytorch\u001b[38;5;241m.\u001b[39mlog_model(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/etu/nn/paraphrase_detection/notebooks/../src/models/train_model.py:57\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, dataloaders, num_epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     loss_val \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[0;32m---> 57\u001b[0m         \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m(outputs, labels)\n\u001b[1;32m     58\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_val, step\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric_name, metric \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'update'"
     ]
    }
   ],
   "source": [
    "for conf in configs:\n",
    "    run_mlflow_experiment(\n",
    "        conf[:-5],\n",
    "        config_paths + conf,\n",
    "        dataloaders,\n",
    "        10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maslab_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
